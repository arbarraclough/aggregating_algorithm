\section{Conclusion}\label{section:conclusion}
\subsection{Summary of Findings}\label{subsection:summary_of_findings}
This study aimed to use the Aggregating Algorithm for Specialist Experts to provide a novel insight into the well-documented understanding that humans have difficulty in producing truly random sequences due to cognitive biases and subconscious patterns.

The chi-square tests detailed in Section~\ref{subsection:chi-square_goodness-of-fit} consistently rejected the null hypothesis that humans are good randomisers, indicating deviations from objective randomness in line with previous research~\cite{nickerson:2009}. The plots of difference further confirmed this, achieving a prediction accuracy of 69.19\% on average and implying predictability. This was reflected in the plots consistently below the x-axis, where an individual Expert's predictions were consistently more accurate than the Learner's.

While the individual data deviated from what was expected of true randomness, when the participants' data was aggregated, it showed qualitative similarities. While these similarities do not equate to true randomness, the aggregate tended towards the distribution of a random process, confirming that by aggregating data, the effects of individual biases become increasingly smaller. Ultimately, these results align with the Cognitive Psychology literature, reinforcing the idea that humans struggle to produce truly random outputs, and contribute to the body of research illustrating that human-generated sequences are often more predictable than expected, despite a conscious effort to be random.

\subsection{Limitations}\label{subsection:limitations}
While this study's findings are significant, certain limitations must be acknowledged and addressed in future research.

The first limitation relates to computational power; The AASE implementation was restricted to analysing prefixes up to length 4 as a compromise between computational efficiency and predictive performance. However, considering longer prefixes\textemdash{}extending to the limits of short-term memory\textemdash{}could uncover more intricate and nuanced patterns in human-generated sequences that were previously undetectable.

A second limitation is the small sample size. With only seven participants, individual data heavily influenced the overall results, which limits the study's generalisability. A larger, more diverse sample would minimise this effect and offer a broader evaluation of human randomisation behaviour.

Additionally, future work could extend the Game to consider a \textit{prediction} and \textit{outcome space} that encompasses the entire alphabet, rather than just binary sequences. This would allow the exploration of more complex randomisation tasks, such as the ability to generate random passwords. This could have significant implications for cybersecurity, exposing the weaknesses of human-generated randomness in contexts where security is essential.

\subsection{How to Use the Project}\label{subsection:how_to_use_the_project}
As mentioned in Subsection~\ref{subsection:procedure}, the application is hosted on GitHub Pages, however, it can be run locally from \verb|./aggregating_algorithm/| with:
\begin{center}
    \verb|npm run start|
\end{center}

To use the project, navigate to the website and follow the instructions provided on-screen to conduct the experiment. Once the experiment has concluded, the JSON will be available to download and stored within the directory \verb|./aggregating_algorithm/results/data|. Once moved, one can run the Python script for generating the plots shown in this report by executing the following command from \verb|./aggregating_algorithm/results/|:

\begin{center}
    \verb|python3 generate_plots.py|
\end{center}

\subsection{Self-Assessment}\label{subsection:self-assessment}
This dissertation has been an incredible journey and I am incredibly proud of the result. Not only has it deepened my understanding of the Aggregating Algorithm, but it has also taught me how to manage a personal project. Overall, I can confidently say that the project was a success, both in achieving the objectives outlined in Chapter~\ref{section:introduction} and in preparing for my career. 

This is not to say that the project was not without its challenges. While I was familiar with Python, developing a web application with React.js was a new experience and required more time to learn than originally anticipated which caused delays in my project's timeline that could have been avoided with more cautious planning.

Despite this, the experience has significantly boosted my confidence as a future Machine Learning Engineer. I have learned the value of setting realistic deadlines, how to effectively use online resources, and how to stay current with research\textemdash{}all invaluable skills in the future. Looking ahead, I plan to explore the \textbf{Mixture of Experts (MoE)} ensemble technique as it is conceptually similar to Prediction with Expert Advice, with applications in neural networks which are extremely relevant currently.